---
title: "F5-TTSï¼šä¸€ä¸ªä¼ªé€ æµåˆ©ä¸å¿ å®è¯­éŸ³çš„ç«¥è¯æ•…äº‹ç”Ÿæˆå·¥å…·"
slug: f5-tts-fairytale-speech-synthesis
description: |
  F5-TTS æ˜¯ä¸€æ¬¾é€šè¿‡æµé‡åŒ¹é…ç”Ÿæˆæµåˆ©å¿ å®è¯­éŸ³çš„ç«¥è¯æ•…äº‹å·¥å…·ï¼ŒåŸºäºæ‰©æ•£å˜å‹å™¨å’Œ ConvNeXt V2ã€‚è¯¥å·¥å…·æ”¯æŒå¤šç§è¯­è¨€ï¼Œæä¾›äº†å¿«é€Ÿçš„æ¨ç†ä¸è®­ç»ƒæ–¹æ³•ã€‚ç«‹å³ä½“éªŒï¼Œæå‡æ‚¨çš„è¯­éŸ³åˆæˆæ•ˆæœï¼
tags: 
  - AI
  - opensource
  - tts
pubDatetime: 2025-08-21T10:26:20+08:00
ogImage: https://opengraph.githubassets.com/4b8514916fe4172a95dc0cc5f0e0f3fb6078a719aef1a410a18dbd16ccbc9c28/SWivid/F5-TTS
---

[åŸæ–‡é“¾æ¥](https://github.com/SWivid/F5-TTS)

---

# F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow MatchingF5-TTSï¼šé€šè¿‡æµé‡åŒ¹é…ä¼ªé€ æµåˆ©å¿ å®è¯­éŸ³çš„ç«¥è¯æ•…äº‹

[](#f5-tts-a-fairytaler-that-fakes-fluent-and-faithful-speech-with-flow-matching)

[![python](https://camo.githubusercontent.com/729dd5f03bac108f24899b73fa15736c1e2a953c81cf0ca13c3c4913f11f4c26/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d332e31302d627269676874677265656e)](https://github.com/SWivid/F5-TTS) [![arXiv](https://camo.githubusercontent.com/8c97b85cae0e49a09ad6842ab2c9c80caba9639b3826192eef8e451258c5732a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f61725869762d323431302e30363838352d6233316231622e7376673f6c6f676f3d6172586976)](https://arxiv.org/abs/2410.06885) [![demo](https://camo.githubusercontent.com/4f79bac2c13fd77aa7d019ba3747a3c884c4cdaeed7102289323365c72409ddf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769744875622d44656d6f253230706167652d6f72616e67652e737667)](https://swivid.github.io/F5-TTS/) [![hfspace](https://camo.githubusercontent.com/35ac16d7b4178e35196575e1069538b7a92958d0f8dbd2edf6e712b8e709fbe5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2546302539462541342539372d537061636525323064656d6f2d79656c6c6f77)](https://huggingface.co/spaces/mrfakename/E2-F5-TTS) [![msspace](https://camo.githubusercontent.com/7f0eb0fb9b09c265fcfc997bc46384507fe7782b929c66a7c51f01dd2a47bfc7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2546302539462541342539362d537061636525323064656d6f2d626c7565)](https://modelscope.cn/studios/modelscope/E2-F5-TTS) [![lab](https://camo.githubusercontent.com/40d03f48fc249b11708e45792f18d52312b72de09d4d1f5439f7f111774cd2ad/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f582d2d4c414e43452d4c61622d677265793f6c6162656c436f6c6f723d6c6967687467726579)](https://x-lance.sjtu.edu.cn/) [![lab](https://camo.githubusercontent.com/91a1ad32b58ceff07f77c59d7b5b0b4fec3d65eb143c3027fde576af7f0c0610/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f50656e672532304368656e672d4c61622d677265793f6c6162656c436f6c6f723d6c6967687467726579)](https://www.pcl.ac.cn)

**F5-TTS**: Diffusion Transformer with ConvNeXt V2, faster trained and inference.**F5-TTS**ï¼šé‡‡ç”¨ ConvNeXt V2 çš„æ‰©æ•£å˜å‹å™¨ï¼Œè®­ç»ƒå’Œæ¨ç†é€Ÿåº¦æ›´å¿«ã€‚

**E2 TTS**: Flat-UNet Transformer, closest reproduction from [paper](https://arxiv.org/abs/2406.18009).**E2 TTS**ï¼šFlat-UNet Transformerï¼Œæœ€æ¥è¿‘[çº¸å¼ ](https://arxiv.org/abs/2406.18009)å¤åˆ¶å“ã€‚

**Sway Sampling**: Inference-time flow step sampling strategy, greatly improves performance**æ‘‡æ‘†é‡‡æ ·&#x20;**ï¼šæ¨ç†æ—¶é—´æµæ­¥é•¿é‡‡æ ·ç­–ç•¥ï¼Œå¤§å¹…æå‡æ€§èƒ½

### Thanks to all the contributors !æ„Ÿè°¢æ‰€æœ‰è´¡çŒ®è€…ï¼

[](#thanks-to-all-the-contributors-)

## NewsÂ Â æ–°é—»

[](#news)

* **2025/03/12**: ğŸ”¥ F5-TTS v1 base model with better training and inference performance. [Few demo](https://swivid.github.io/F5-TTS_updates).**2025/03/12**ï¼š ğŸ”¥ F5-TTS v1 åŸºç¡€æ¨¡å‹ï¼Œå…·æœ‰æ›´å¥½çš„è®­ç»ƒå’Œæ¨ç†æ€§èƒ½ã€‚[ å¾ˆå°‘æœ‰æ¼”ç¤º ](https://swivid.github.io/F5-TTS_updates)ã€‚
* **2024/10/08**: F5-TTS & E2 TTS base models on [ğŸ¤— Hugging Face](https://huggingface.co/SWivid/F5-TTS), [ğŸ¤– Model Scope](https://www.modelscope.cn/models/SWivid/F5-TTS_Emilia-ZH-EN), [ğŸŸ£ Wisemodel](https://wisemodel.cn/models/SJTU_X-LANCE/F5-TTS_Emilia-ZH-EN).**2024/10/08**ï¼š [Hugging Faceã€Model Scopeã€Wisemodel ä¸Šçš„ ğŸ¤—](https://huggingface.co/SWivid/F5-TTS) F5-TTS å’Œ E2 TTS åŸºç¡€æ¨¡å‹ã€‚ [ğŸŸ£](https://wisemodel.cn/models/SJTU_X-LANCE/F5-TTS_Emilia-ZH-EN) [ğŸ¤–](https://www.modelscope.cn/models/SWivid/F5-TTS_Emilia-ZH-EN)

## InstallationÂ Â å®‰è£…

[](#installation)

### Create a separate environment if neededå¦‚æœéœ€è¦ï¼Œè¯·åˆ›å»ºå•ç‹¬çš„ç¯å¢ƒ

[](#create-a-separate-environment-if-needed)

```
# Create a python 3.10 conda env (you could also use virtualenv)
conda create -n f5-tts python=3.10
conda activate f5-tts
```

### Install PyTorch with matched deviceä½¿ç”¨åŒ¹é…çš„è®¾å¤‡å®‰è£… PyTorch

[](#install-pytorch-with-matched-device)

NVIDIA GPUÂ Â è‹±ä¼Ÿè¾¾ GPU

> ```
> # Install pytorch with your CUDA version, e.g.
> pip install torch==2.4.0+cu124 torchaudio==2.4.0+cu124 --extra-index-url https://download.pytorch.org/whl/cu124
> ```

AMD GPUÂ Â AMD æ˜¾å¡

> ```
> # Install pytorch with your ROCm version (Linux only), e.g.
> pip install torch==2.5.1+rocm6.2 torchaudio==2.5.1+rocm6.2 --extra-index-url https://download.pytorch.org/whl/rocm6.2
> ```

Intel GPUÂ Â è‹±ç‰¹å°” GPU

> ```
> # Install pytorch with your XPU version, e.g.
> # IntelÂ® Deep Learning Essentials or IntelÂ® oneAPI Base Toolkit must be installed
> pip install torch torchaudio --index-url https://download.pytorch.org/whl/test/xpu
>
> # Intel GPU support is also available through IPEX (IntelÂ® Extension for PyTorch)
> # IPEX does not require the IntelÂ® Deep Learning Essentials or IntelÂ® oneAPI Base Toolkit
> # See: https://pytorch-extension.intel.com/installation?request=platform
> ```

Apple SiliconÂ Â è‹¹æœç¡…

> ```
> # Install the stable pytorch, e.g.
> pip install torch torchaudio
> ```

### Then you can choose one from below:ç„¶åæ‚¨å¯ä»¥ä»ä»¥ä¸‹ä¸­é€‰æ‹©ä¸€ä¸ªï¼š

[](#then-you-can-choose-one-from-below)

> ### 1. As a pip package (if just for inference)1. ä½œä¸º pip åŒ…ï¼ˆå¦‚æœåªæ˜¯ä¸ºäº†æ¨ç†ï¼‰
>
> [](#1-as-a-pip-package-if-just-for-inference)
>
> ```
> pip install f5-tts
> ```
>
> ### 2. Local editable (if also do training, finetuning)2. æœ¬åœ°å¯ç¼–è¾‘ï¼ˆå¦‚æœä¹Ÿåšè®­ç»ƒã€å¾®è°ƒï¼‰
>
> [](#2-local-editable-if-also-do-training-finetuning)
>
> ```
> git clone https://github.com/SWivid/F5-TTS.git
> cd F5-TTS
> # git submodule update --init --recursive  # (optional, if use bigvgan as vocoder)
> pip install -e .
> ```

### Docker usage also availableä¹Ÿæä¾› Docker ä½¿ç”¨

[](#docker-usage-also-available)

```
# Build from Dockerfile
docker build -t f5tts:v1 .

# Run from GitHub Container Registry
docker container run --rm -it --gpus=all --mount 'type=volume,source=f5-tts,target=/root/.cache/huggingface/hub/' -p 7860:7860 ghcr.io/swivid/f5-tts:main

# Quickstart if you want to just run the web interface (not CLI)
docker container run --rm -it --gpus=all --mount 'type=volume,source=f5-tts,target=/root/.cache/huggingface/hub/' -p 7860:7860 ghcr.io/swivid/f5-tts:main f5-tts_infer-gradio --host 0.0.0.0
```

### RuntimeÂ Â è¿è¡Œ

[](#runtime)

Deployment solution with Triton and TensorRT-LLM.ä½¿ç”¨ Triton å’Œ TensorRT-LLM çš„éƒ¨ç½²è§£å†³æ–¹æ¡ˆã€‚

#### Benchmark ResultsÂ Â åŸºå‡†æµ‹è¯•ç»“æœ

[](#benchmark-results)

Decoding on a single L20 GPU, using 26 different prompt\_audio & target\_text pairs, 16 NFE.åœ¨å•ä¸ª L20 GPU ä¸Šè§£ç ï¼Œä½¿ç”¨ 26 ä¸ªä¸åŒçš„ prompt\_audio å’Œ target\_text å¯¹ï¼Œ16 ä¸ª NFEã€‚

| Model                                  | ConcurrencyÂ Â å¹¶å‘                  | Avg LatencyÂ Â å¹³å‡å»¶è¿Ÿ | RTF    | ModeÂ Â æ¨¡å¼                    |
| -------------------------------------- | -------------------------------- | ----------------- | ------ | --------------------------- |
| F5-TTS Base (Vocos)Â Â F5-TTS åº•åº§ ï¼ˆVocosï¼‰ | 2                                | 253 msÂ Â 253 æ¯«ç§’    | 0.0394 | Client-ServerÂ Â å®¢æˆ·ç«¯-æœåŠ¡å™¨      |
| F5-TTS Base (Vocos)Â Â F5-TTS åº•åº§ ï¼ˆVocosï¼‰ | 1 (Batch\_size)Â Â 1 ï¼ˆBatch\_sizeï¼‰ | -                 | 0.0402 | Offline TRT-LLMÂ Â ç¦»çº¿ TRT-LLM |
| F5-TTS Base (Vocos)Â Â F5-TTS åº•åº§ ï¼ˆVocosï¼‰ | 1 (Batch\_size)Â Â 1 ï¼ˆBatch\_sizeï¼‰ | -                 | 0.1467 | Offline PytorchÂ Â ç¦»çº¿ Pytorch |

See [detailed instructions](https://github.com/SWivid/F5-TTS/blob/main/src/f5_tts/runtime/triton_trtllm/README.md) for more information.æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[è¯¦ç»†è¯´æ˜ ](https://github.com/SWivid/F5-TTS/blob/main/src/f5_tts/runtime/triton_trtllm/README.md)ã€‚

## InferenceÂ Â æ¨ç†

[](#inference)

* In order to achieve desired performance, take a moment to read [detailed guidance](https://github.com/SWivid/F5-TTS/blob/main/src/f5_tts/infer).ä¸ºäº†è¾¾åˆ°é¢„æœŸçš„æ€§èƒ½ï¼Œè¯·èŠ±ç‚¹æ—¶é—´é˜…è¯»[è¯¦ç»†æŒ‡å— ](https://github.com/SWivid/F5-TTS/blob/main/src/f5_tts/infer)ã€‚
* By properly searching the keywords of problem encountered, [issues](https://github.com/SWivid/F5-TTS/issues?q=is%3Aissue) are very helpful.é€šè¿‡æ­£ç¡®æœç´¢é‡åˆ°é—®é¢˜çš„å…³é”®è¯ï¼Œ[ é—®é¢˜](https://github.com/SWivid/F5-TTS/issues?q=is%3Aissue)éå¸¸æœ‰å¸®åŠ©ã€‚

### 1. Gradio AppÂ Â 1. Gradio åº”ç”¨ç¨‹åº

[](#1-gradio-app)

Currently supported features:å½“å‰æ”¯æŒçš„åŠŸèƒ½ï¼š

* Basic TTS with Chunk Inferenceå…·æœ‰å—æ¨ç†çš„åŸºæœ¬ TTS
* Multi-Style / Multi-Speaker Generationå¤šé£æ ¼/å¤šæ‰¬å£°å™¨ç”Ÿæˆ
* Voice Chat powered by Qwen2.5-3B-Instructè¯­éŸ³èŠå¤© powered by Qwen2.5-3B-Instruct
* [Custom inference with more language supportå…·æœ‰æ›´å¤šè¯­è¨€æ”¯æŒçš„è‡ªå®šä¹‰æ¨ç†](https://github.com/SWivid/F5-TTS/blob/main/src/f5_tts/infer/SHARED.md)

```
# Launch a Gradio app (web interface)
f5-tts_infer-gradio

# Specify the port/host
f5-tts_infer-gradio --port 7860 --host 0.0.0.0

# Launch a share link
f5-tts_infer-gradio --share
```

NVIDIA device docker compose file exampleNVIDIA è®¾å¤‡ docker compose æ–‡ä»¶ç¤ºä¾‹

```
services:
  f5-tts:
    image: ghcr.io/swivid/f5-tts:main
    ports:
      - "7860:7860"
    environment:
      GRADIO_SERVER_PORT: 7860
    entrypoint: ["f5-tts_infer-gradio", "--port", "7860", "--host", "0.0.0.0"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

volumes:
  f5-tts:
    driver: local
```

### 2. CLI InferenceÂ Â 2. CLI æ¨ç†

[](#2-cli-inference)

```
# Run with flags
# Leave --ref_text "" will have ASR model transcribe (extra GPU memory usage)
f5-tts_infer-cli --model F5TTS_v1_Base \
--ref_audio "provide_prompt_wav_path_here.wav" \
--ref_text "The content, subtitle or transcription of reference audio." \
--gen_text "Some text you want TTS model generate for you."

# Run with default setting. src/f5_tts/infer/examples/basic/basic.toml
f5-tts_infer-cli
# Or with your own .toml file
f5-tts_infer-cli -c custom.toml

# Multi voice. See src/f5_tts/infer/README.md
f5-tts_infer-cli -c src/f5_tts/infer/examples/multi/story.toml
```

## TrainingÂ Â è®­ç»ƒ

[](#training)

### 1. With Hugging Face Accelerate1. ä¸ Hugging Face Accelerate

[](#1-with-hugging-face-accelerate)

Refer to [training & finetuning guidance](https://github.com/SWivid/F5-TTS/blob/main/src/f5_tts/train) for best practice.æœ‰å…³æœ€ä½³å®è·µï¼Œè¯·å‚é˜…[åŸ¹è®­å’Œå¾®è°ƒæŒ‡å— ](https://github.com/SWivid/F5-TTS/blob/main/src/f5_tts/train)ã€‚

### 2. With Gradio AppÂ Â 2. ä½¿ç”¨ Gradio åº”ç”¨ç¨‹åº

[](#2-with-gradio-app)

```
# Quick start with Gradio web interface
f5-tts_finetune-gradio
```

Read [training & finetuning guidance](https://github.com/SWivid/F5-TTS/blob/main/src/f5_tts/train) for more instructions.é˜…è¯»[åŸ¹è®­å’Œå¾®è°ƒæŒ‡å—ä»¥](https://github.com/SWivid/F5-TTS/blob/main/src/f5_tts/train)è·å–æ›´å¤šè¯´æ˜ã€‚

## [EvaluationÂ Â è¯„ä¼°](https://github.com/SWivid/F5-TTS/blob/main/src/f5_tts/eval)

[](#evaluation)

## DevelopmentÂ Â å‘å±•

[](#development)

Use pre-commit to ensure code quality (will run linters and formatters automatically):ä½¿ç”¨é¢„æäº¤æ¥ç¡®ä¿ä»£ç è´¨é‡ï¼ˆå°†è‡ªåŠ¨è¿è¡Œ linter å’Œæ ¼å¼åŒ–ç¨‹åºï¼‰ï¼š

```
pip install pre-commit
pre-commit install
```

When making a pull request, before each commit, run:åœ¨å‘å‡ºæ‹‰å–è¯·æ±‚æ—¶ï¼Œåœ¨æ¯æ¬¡æäº¤ä¹‹å‰ï¼Œè¿è¡Œï¼š

```
pre-commit run --all-files
```

Note: Some model components have linting exceptions for E722 to accommodate tensor notation.æ³¨æ„ï¼šæŸäº›æ¨¡å‹ç»„ä»¶å¯¹ E722 å…·æœ‰ linting ä¾‹å¤–ï¼Œä»¥é€‚åº”å¼ é‡è¡¨ç¤ºæ³•ã€‚

## AcknowledgementsÂ Â ç¡®è®¤

[](#acknowledgements)

* [E2-TTS](https://arxiv.org/abs/2406.18009) brilliant work, simple and effective[E2-TTS](https://arxiv.org/abs/2406.18009) ç²¾å½©å·¥ä½œï¼Œç®€å•æœ‰æ•ˆ
* [Emilia](https://arxiv.org/abs/2407.05361), [WenetSpeech4TTS](https://arxiv.org/abs/2406.05763), [LibriTTS](https://arxiv.org/abs/1904.02882), [LJSpeech](https://keithito.com/LJ-Speech-Dataset/) valuable datasets[Emilia](https://arxiv.org/abs/2407.05361)ã€[WenetSpeech4TTS](https://arxiv.org/abs/2406.05763)ã€[LibriTTS](https://arxiv.org/abs/1904.02882)ã€[LJSpeech](https://keithito.com/LJ-Speech-Dataset/) æœ‰ä»·å€¼çš„æ•°æ®é›†
* [lucidrains](https://github.com/lucidrains) initial CFM structure with also [bfs18](https://github.com/bfs18) for discussion[lucidrains](https://github.com/lucidrains) åˆå§‹ CFM ç»“æ„ä¸ [bfs18](https://github.com/bfs18) è¿›è¡Œè®¨è®º
* [SD3](https://arxiv.org/abs/2403.03206) & [Hugging Face diffusers](https://github.com/huggingface/diffusers) DiT and MMDiT code structure[SD3](https://arxiv.org/abs/2403.03206) & [Hugging Face æ‰©æ•£å™¨ ](https://github.com/huggingface/diffusers)DiT å’Œ MMDiT ä»£ç ç»“æ„
* [torchdiffeq](https://github.com/rtqichen/torchdiffeq) as ODE solver, [Vocos](https://huggingface.co/charactr/vocos-mel-24khz) and [BigVGAN](https://github.com/NVIDIA/BigVGAN) as vocoder[torchdiffeq](https://github.com/rtqichen/torchdiffeq) ä½œä¸º ODE æ±‚è§£å™¨ï¼Œ[Vocos](https://huggingface.co/charactr/vocos-mel-24khz) å’Œ [BigVGAN](https://github.com/NVIDIA/BigVGAN) ä½œä¸ºå£°ç å™¨
* [FunASR](https://github.com/modelscope/FunASR), [faster-whisper](https://github.com/SYSTRAN/faster-whisper), [UniSpeech](https://github.com/microsoft/UniSpeech), [SpeechMOS](https://github.com/tarepan/SpeechMOS) for evaluation tools[FunASR](https://github.com/modelscope/FunASR)ã€[faster-whisper](https://github.com/SYSTRAN/faster-whisper)ã€[UniSpeech](https://github.com/microsoft/UniSpeech)ã€[SpeechMOS](https://github.com/tarepan/SpeechMOS) è¯„ä¼°å·¥å…·
* [ctc-forced-aligner](https://github.com/MahmoudAshraf97/ctc-forced-aligner) for speech edit testç”¨äºè¯­éŸ³ç¼–è¾‘æµ‹è¯•çš„ [ctc-forced-aligner](https://github.com/MahmoudAshraf97/ctc-forced-aligner)
* [mrfakename](https://x.com/realmrfakename) huggingface space demo \~[MrFakeName](https://x.com/realmrfakename) HuggingFace ç©ºé—´æ¼”ç¤º \~
* [f5-tts-mlx](https://github.com/lucasnewman/f5-tts-mlx/tree/main) Implementation with MLX framework by [Lucas Newman](https://github.com/lucasnewman)[F5-TTS-MLX](https://github.com/lucasnewman/f5-tts-mlx/tree/main)[Lucas Newman](https://github.com/lucasnewman) ä½¿ç”¨ MLX æ¡†æ¶å®ç°
* [F5-TTS-ONNX](https://github.com/DakeQQ/F5-TTS-ONNX) ONNX Runtime version by [DakeQQ](https://github.com/DakeQQ)[F5-TTS-ONNX](https://github.com/DakeQQ/F5-TTS-ONNX)[DakeQQ](https://github.com/DakeQQ) çš„ ONNX è¿è¡Œæ—¶ç‰ˆæœ¬
* [Yuekai Zhang](https://github.com/yuekaizhang) Triton and TensorRT-LLM support \~[å¼ è·ƒå‡¯ ](https://github.com/yuekaizhang)Triton å’Œ TensorRT-LLM æ”¯æŒ \~

## CitationÂ Â å¼•æ–‡

[](#citation)

If our work and codebase is useful for you, please cite as:å¦‚æœæˆ‘ä»¬çš„å·¥ä½œå’Œä»£ç åº“å¯¹æ‚¨æœ‰ç”¨ï¼Œè¯·å¼•ç”¨ï¼š

```
@article{chen-etal-2024-f5tts,
      title={F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching}, 
      author={Yushen Chen and Zhikang Niu and Ziyang Ma and Keqi Deng and Chunhui Wang and Jian Zhao and Kai Yu and Xie Chen},
      journal={arXiv preprint arXiv:2410.06885},
      year={2024},
}
```

## LicenseÂ Â è®¸å¯è¯

[](#license)

Our code is released under MIT License. The pre-trained models are licensed under the CC-BY-NC license due to the training data Emilia, which is an in-the-wild dataset. Sorry for any inconvenience this may cause.æˆ‘ä»¬çš„ä»£ç æ˜¯åœ¨ MIT è®¸å¯ä¸‹å‘å¸ƒçš„ã€‚ç”±äºè®­ç»ƒæ•°æ® Emiliaï¼Œé¢„è®­ç»ƒæ¨¡å‹åœ¨ CC-BY-NC è®¸å¯ä¸‹è·å¾—è®¸å¯ï¼Œè¿™æ˜¯ä¸€ä¸ªé‡å¤–æ•°æ®é›†ã€‚å¯¹äºç”±æ­¤é€ æˆçš„ä»»ä½•ä¸ä¾¿ï¼Œæˆ‘ä»¬æ·±è¡¨æ­‰æ„ã€‚


